{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nfrom PIL import Image","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport os","metadata":{"execution":{"iopub.status.busy":"2023-11-18T22:15:02.075244Z","iopub.execute_input":"2023-11-18T22:15:02.075594Z","iopub.status.idle":"2023-11-18T22:15:02.082301Z","shell.execute_reply.started":"2023-11-18T22:15:02.075571Z","shell.execute_reply":"2023-11-18T22:15:02.080077Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/UBC-OCEAN\"\nOUTPUT_DIR = \"/kaggle/working/ubc-ocean-tiles\"\nTRAIN_CSV = os.path.join(DATA_DIR, \"train.csv\")\nTRAIN_IMGS = os.path.join(DATA_DIR, \"train_images\")","metadata":{"execution":{"iopub.status.busy":"2023-11-18T22:15:40.549776Z","iopub.execute_input":"2023-11-18T22:15:40.551221Z","iopub.status.idle":"2023-11-18T22:15:40.557129Z","shell.execute_reply.started":"2023-11-18T22:15:40.551148Z","shell.execute_reply":"2023-11-18T22:15:40.555748Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"data_df = pd.read_csv(TRAIN_CSV) \ndata_df[\"path\"] = [os.path.join(TRAIN_IMGS, f\"{str(i)}.png\")\n                   for i in data_df[\"image_id\"]]\n","metadata":{"execution":{"iopub.status.busy":"2023-11-18T22:15:49.334346Z","iopub.execute_input":"2023-11-18T22:15:49.334705Z","iopub.status.idle":"2023-11-18T22:15:49.360568Z","shell.execute_reply.started":"2023-11-18T22:15:49.334677Z","shell.execute_reply":"2023-11-18T22:15:49.359501Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# roubar as coisas do agrotech\n# fazer o split para 2048x2048\n# resize para 256x256","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_image_tiles(p_img, out_folder, size: int = 768, scale: float = 1.0, drop_thr: float = 0.8) -> list:\n    name, _ = os.path.splitext(os.path.basename(p_img))\n    im = pyvips.Image.new_from_file(p_img)\n    w = h = size\n    # https://stackoverflow.com/a/47581978/4521646\n    idxs = [(y, y + h, x, x + w) for y in range(0, im.height, h) for x in range(0, im.width, w)]\n    files = []\n    for k, (y, y_, x, x_) in enumerate(idxs):\n        # https://libvips.github.io/pyvips/vimage.html#pyvips.Image.crop\n        tile = im.crop(x, y, min(w, im.width - x), min(h, im.height - y)).numpy()[..., :3]\n        if tile.shape[:2] != (h, w):\n            tile_ = tile\n            tile_size = (h, w) if tile.ndim == 2 else (h, w, tile.shape[2])\n            tile = np.zeros(tile_size, dtype=tile.dtype)\n            tile[:tile_.shape[0], :tile_.shape[1], ...] = tile_\n        mask_bg = np.sum(tile, axis=2) == 0\n        if np.sum(mask_bg) >= (np.prod(mask_bg.shape) * drop_thr):\n            #print(f\"skip almost empty tile: {k:06}_{int(x_ / w)}-{int(y_ / h)}\")\n            continue\n        tile[mask_bg, :] = 255\n        mask_bg = np.mean(tile, axis=2) > 240\n        if np.sum(mask_bg) >= (np.prod(mask_bg.shape) * drop_thr):\n            #print(f\"skip almost empty tile: {k:06}_{int(x_ / w)}-{int(y_ / h)}\")\n            continue\n        p_img = os.path.join(folder, f\"{k:06}_{int(x_ / w)}-{int(y_ / h)}.png\")\n        # print(tile.shape, tile.dtype, tile.min(), tile.max())\n        new_size = int(size * scale), int(size * scale)\n        Image.fromarray(tile).resize(new_size, Image.LANCZOS).save(p_img)\n        files.append(p_img)\n    return files, idxs","metadata":{"execution":{"iopub.status.busy":"2023-11-18T22:18:51.188372Z","iopub.execute_input":"2023-11-18T22:18:51.188766Z","iopub.status.idle":"2023-11-18T22:18:51.199130Z","shell.execute_reply.started":"2023-11-18T22:18:51.188734Z","shell.execute_reply":"2023-11-18T22:18:51.197726Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"0       9.5140\n1      19.5484\n2       1.3552\n3      16.9236\n4      14.8816\n        ...   \n533    21.3420\n534    22.0168\n535    30.3440\n536    17.0204\n537    18.0760\nName: image_width, Length: 538, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]}]}